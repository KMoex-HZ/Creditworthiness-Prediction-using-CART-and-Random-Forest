---
title: "Creditworthiness Prediction using CART and Random Forest"
author: "Khairunnisa Maharani"
date: "2025-06-07"
output: 
  html_document:
    theme: flatly
    highlight: tango
    toc: true
    toc_float: true
    code_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
    echo = TRUE,
    warning = FALSE,
    message = FALSE,
    fig.width = 10,
    fig.height = 6,
    fig.align = "center"
)
```

# üìä Creditworthiness Prediction Analysis

This project explores the prediction of creditworthiness using machine learning, specifically Decision Tree (CART) and Random Forest algorithms. It handles class imbalance using ROSE and compares model performance with various configurations.

## üóÉÔ∏è Dataset Description

-   **Dataset**: German Credit Dataset from UCI ML Repository
-   **Samples**: 1000 customers
-   **Target Variable**: Creditworthiness (`Good` or `Bad`)
-   **Features**: 20 predictor variables (demographic and financial attributes)

------------------------------------------------------------------------

## 1. Load Required Libraries

```{r load-libraries}
# Core data manipulation and visualization
library(tidyverse)
library(ggplot2)
library(gridExtra)
library(corrplot)
library(knitr)

# Machine learning libraries
library(rpart)
library(rpart.plot)
library(randomForest)
library(caret)

# Model evaluation and handling imbalanced data
library(ROSE)
library(pROC)

# Additional visualization and analysis
library(visdat)
library(naniar)
library(skimr)
library(DT)

# Set theme for consistent plots
theme_set(theme_minimal())
```

------------------------------------------------------------------------

## 2. Data Loading and Initial Exploration

```{r data-loading}
# Load dataset
data <- read.csv("german_data.csv")

# Basic data exploration
cat("Dataset dimensions:", dim(data), "\n")
cat("Dataset structure:\n")
str(data)
```

```{r data-summary}
# Comprehensive data summary using skimr
skim_result <- skim(data)
print(skim_result)
```

------------------------------------------------------------------------

## 3. Data Quality Assessment

```{r missing-values}
# Check for missing values
missing_values <- colSums(is.na(data))
missing_percentage <- (missing_values / nrow(data)) * 100
missing_df <- data.frame(
    Missing_Count = missing_values, 
    Missing_Percentage = missing_percentage
)

# Display missing values if any
if(sum(missing_values) > 0) {
    cat("Missing Values Summary:\n")
    print(missing_df[missing_df$Missing_Count > 0, ])
    
    # Visualize missing values pattern
    vis_miss(data, cluster = TRUE)
    gg_miss_var(data)
} else {
    cat("‚úÖ No missing values found in the dataset!\n")
}
```

```{r data-preprocessing}
# Convert categorical variables to factors
categorical_vars <- names(data)[sapply(data, is.character)]
for(var in categorical_vars) {
    data[[var]] <- as.factor(data[[var]])
}

# Convert target variable to factor with proper levels
data$Kelayakan.Kredit <- factor(data$Kelayakan.Kredit, levels = c("Buruk", "Baik"))

cat("Categorical variables converted:", length(categorical_vars), "variables\n")
```

------------------------------------------------------------------------

## 4. Exploratory Data Analysis (EDA)

### 4.1 Target Variable Distribution

```{r target-distribution}
# Calculate target distribution
target_dist <- table(data$Kelayakan.Kredit)
target_prop <- prop.table(target_dist) * 100

# Visualize target distribution
plt_target <- ggplot(data, aes(x = Kelayakan.Kredit, fill = Kelayakan.Kredit)) +
    geom_bar(alpha = 0.8) +
    geom_text(stat = "count", 
              aes(label = paste0(scales::percent(after_stat(count)/sum(after_stat(count))), 
                                "\n(n=", after_stat(count), ")")), 
              vjust = -0.5, size = 4) +
    scale_fill_manual(values = c("Baik" = "#2E8B57", "Buruk" = "#DC143C")) +
    labs(title = "Distribution of Credit Worthiness", 
         subtitle = paste("Good:", round(target_prop[2], 1), "% | Bad:", round(target_prop[1], 1), "%"),
         x = "Credit Worthiness", 
         y = "Count") +
    theme(legend.position = "none")

print(plt_target)
```

### 4.2 Categorical Variables Analysis

```{r categorical-analysis}
# Function to create proportion plots for categorical variables
plot_categorical_variable <- function(data, var_name) {
    prop_df <- data %>%
        group_by(!!sym(var_name), Kelayakan.Kredit) %>%
        summarise(count = n(), .groups = "drop") %>%
        group_by(!!sym(var_name)) %>%
        mutate(
            prop = count / sum(count),
            total = sum(count)
        )
    
    ggplot(prop_df, aes(x = !!sym(var_name), y = prop, fill = Kelayakan.Kredit)) +
        geom_bar(stat = "identity", position = "fill", alpha = 0.8) +
        geom_text(aes(label = paste0(round(prop*100), "%")), 
                  position = position_fill(vjust = 0.5), size = 3) +
        scale_fill_manual(values = c("Baik" = "#2E8B57", "Buruk" = "#DC143C")) +
        labs(title = paste("Credit Worthiness Proportion by", gsub("\\.", " ", var_name)),
             x = gsub("\\.", " ", var_name), 
             y = "Proportion",
             fill = "Credit Worthiness") +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
}

# Important categorical variables to analyze
important_cat_vars <- c("Status.Rekening", "Riwayat.Kredit", "Tujuan.Kredit", 
                       "Tabungan.Bonds", "Pekerjaan.Saat.Ini", 
                       "Status.Pribadi.dan.Jenis.Kelamin", "Properti")

# Generate plots for categorical variables
cat_plots <- map(important_cat_vars, ~plot_categorical_variable(data, .x))
names(cat_plots) <- important_cat_vars

# Display plots
walk(cat_plots, print)
```

### 4.3 Numerical Variables Analysis

```{r numerical-analysis}
# Identify numerical variables
numerical_vars <- c("Durasi.dalam.bulan", "Jumlah.Kredit..DM.", "Tingkat.Angsuran....", 
                   "Usia..tahun.", "Jumlah.Kredit.di.Bank.Ini", "Jumlah.Tanggungan")

# Create histograms for numerical variables
create_histogram <- function(data, var_name) {
    ggplot(data, aes_string(x = var_name, fill = "Kelayakan.Kredit")) +
        geom_histogram(position = "dodge", alpha = 0.7, bins = 30) +
        scale_fill_manual(values = c("Baik" = "#2E8B57", "Buruk" = "#DC143C")) +
        labs(title = paste("Distribution of", gsub("\\.", " ", var_name)), 
             x = gsub("\\.", " ", var_name), 
             y = "Frequency",
             fill = "Credit Worthiness") +
        theme_minimal()
}

# Generate histograms
num_histograms <- map(numerical_vars, ~create_histogram(data, .x))
names(num_histograms) <- numerical_vars

# Display histograms
walk(num_histograms, print)
```

```{r numerical-boxplots}
# Create boxplots for numerical variables
create_boxplot <- function(data, var_name) {
    ggplot(data, aes_string(x = "Kelayakan.Kredit", y = var_name, fill = "Kelayakan.Kredit")) +
        geom_boxplot(alpha = 0.7) +
        scale_fill_manual(values = c("Baik" = "#2E8B57", "Buruk" = "#DC143C")) +
        labs(title = paste("Boxplot of", gsub("\\.", " ", var_name), "by Credit Worthiness"),
             x = "Credit Worthiness", 
             y = gsub("\\.", " ", var_name)) +
        theme(legend.position = "none")
}

# Generate boxplots
num_boxplots <- map(numerical_vars, ~create_boxplot(data, .x))
names(num_boxplots) <- numerical_vars

# Display boxplots
walk(num_boxplots, print)
```

### 4.4 Correlation Analysis

```{r correlation-analysis}
# Create numeric version of target for correlation
data$Kelayakan.Kredit.Num <- ifelse(data$Kelayakan.Kredit == "Baik", 1, 0)

# Select numerical variables for correlation analysis
num_data <- data %>% select_if(is.numeric)

# Calculate correlation matrix
corr_matrix <- cor(num_data, use = "complete.obs")

# Visualize correlation matrix
corrplot(corr_matrix, 
         method = "color", 
         type = "upper", 
         tl.col = "black", 
         tl.srt = 45,
         addCoef.col = "black",
         number.cex = 0.7,
         title = "Correlation Matrix of Numerical Variables",
         mar = c(0,0,1,0))
```

------------------------------------------------------------------------

## 5. Data Preprocessing and Model Preparation

```{r data-splitting}
# Prepare data for modeling
model_data <- data %>% select(-Kelayakan.Kredit.Num)

# Split data into training and testing sets
set.seed(123)
train_index <- createDataPartition(model_data$Kelayakan.Kredit, p = 0.7, list = FALSE)
train_data <- model_data[train_index, ]
test_data <- model_data[-train_index, ]

cat("Training set size:", nrow(train_data), "\n")
cat("Test set size:", nrow(test_data), "\n")
cat("Training set class distribution:\n")
print(table(train_data$Kelayakan.Kredit))
```

```{r handle-imbalance}
# Handle class imbalance using ROSE
train_balanced <- ROSE(Kelayakan.Kredit ~ ., data = train_data, seed = 123)$data

cat("Balanced training set class distribution:\n")
print(table(train_balanced$Kelayakan.Kredit))

# Visualize the effect of balancing
balance_comparison <- data.frame(
    Dataset = rep(c("Original", "Balanced"), each = 2),
    Class = rep(c("Buruk", "Baik"), 2),
    Count = c(table(train_data$Kelayakan.Kredit), table(train_balanced$Kelayakan.Kredit))
)

ggplot(balance_comparison, aes(x = Dataset, y = Count, fill = Class)) +
    geom_bar(stat = "identity", position = "dodge", alpha = 0.8) +
    scale_fill_manual(values = c("Baik" = "#2E8B57", "Buruk" = "#DC143C")) +
    labs(title = "Effect of Data Balancing on Class Distribution",
         x = "Dataset Type", y = "Count") +
    geom_text(aes(label = Count), position = position_dodge(width = 0.9), vjust = -0.5)
```

------------------------------------------------------------------------

## 6. CART Model Development

### 6.1 Basic CART Model

```{r cart-model}
# Fit CART model
cart_model <- rpart(
    Kelayakan.Kredit ~ ., 
    data = train_balanced, 
    method = "class",
    control = rpart.control(
        cp = 0.01,
        minbucket = 5,
        minsplit = 10
    )
)

# Print model summary
printcp(cart_model)
```

### 6.2 CART Model Pruning

```{r cart-pruning}
# Build full tree for pruning analysis
cart_model_full <- rpart(
    Kelayakan.Kredit ~ ., 
    data = train_balanced, 
    method = "class",
    control = rpart.control(
        cp = 0.001,
        minbucket = 5,
        minsplit = 10
    )
)

# Plot cross-validation error vs complexity parameter
cp_table <- as.data.frame(cart_model_full$cptable)

ggplot(cp_table, aes(x = CP, y = xerror)) +
    geom_line(color = "blue", size = 1) +
    geom_point(color = "red", size = 2) +
    labs(title = "Cross-validation Error vs Complexity Parameter",
         x = "Complexity Parameter (CP)",
         y = "Cross-validation Error") +
    theme_minimal()

# Find optimal CP using 1-SE rule
min_error <- min(cart_model_full$cptable[,"xerror"])
se_min_error <- cart_model_full$cptable[which.min(cart_model_full$cptable[,"xerror"]), "xstd"]
threshold <- min_error + se_min_error
optimal_cp <- cart_model_full$cptable[cart_model_full$cptable[,"xerror"] <= threshold, "CP"][1]

cat("Optimal CP (1-SE rule):", optimal_cp, "\n")

# Prune the tree
cart_model_pruned <- prune(cart_model_full, cp = optimal_cp)
```

### 6.3 CART Model Visualization

```{r cart-visualization}
# Visualize pruned decision tree
rpart.plot(
    cart_model_pruned,
    type = 4,
    extra = 101,
    box.palette = c("#DC143C", "#2E8B57"),
    branch.lty = 1,
    shadow.col = "gray",
    nn = TRUE,
    tweak = 1.2,
    fallen.leaves = TRUE,
    uniform = TRUE,
    main = "Pruned CART Decision Tree for Credit Worthiness Prediction"
)

# Save high-quality decision tree plot
if(!dir.exists("plots")) dir.create("plots")

pdf("plots/decision_tree_pruned.pdf", width = 12, height = 8)
rpart.plot(
    cart_model_pruned,
    type = 4,
    extra = 101,
    box.palette = c("#DC143C", "#2E8B57"),
    branch.lty = 1,
    shadow.col = "gray",
    nn = TRUE,
    tweak = 1.2,
    fallen.leaves = TRUE,
    uniform = TRUE,
    main = "Pruned CART Decision Tree for Credit Worthiness Prediction"
)
dev.off()

cat("Decision tree saved to: plots/decision_tree_pruned.pdf\n")
```

### 6.4 CART Variable Importance

```{r cart-importance}
# Extract and visualize variable importance
cart_importance <- cart_model_pruned$variable.importance
if(length(cart_importance) > 0) {
    cart_importance_df <- data.frame(
        Variable = names(cart_importance),
        Importance = as.numeric(cart_importance)
    ) %>%
    arrange(desc(Importance)) %>%
    slice_head(n = 10)
    
    ggplot(cart_importance_df, aes(x = reorder(Variable, Importance), y = Importance)) +
        geom_bar(stat = "identity", fill = "#4CAF50", alpha = 0.8) +
        coord_flip() +
        labs(title = "Top 10 Most Important Variables in CART Model",
             x = "Variables", y = "Importance (Gini Decrease)") +
        theme_minimal()
} else {
    cat("No variable importance information available for pruned model.\n")
}
```

------------------------------------------------------------------------

## 7. Random Forest Model Development

```{r random-forest}
# Fit Random Forest model
set.seed(123)
rf_model <- randomForest(
    Kelayakan.Kredit ~ ., 
    data = train_balanced, 
    ntree = 500,
    mtry = sqrt(ncol(train_balanced) - 1),
    importance = TRUE
)

# Print model summary
print(rf_model)

# Plot error rate
plot(rf_model, main = "Random Forest Error Rate by Number of Trees")
legend("topright", colnames(rf_model$err.rate), col = 1:3, lty = 1:3)
```

```{r rf-importance}
# Extract and visualize variable importance
rf_importance <- importance(rf_model, type = 1)
rf_importance_df <- data.frame(
    Variable = rownames(rf_importance),
    MeanDecreaseAccuracy = rf_importance[, "MeanDecreaseAccuracy"]
) %>%
arrange(desc(MeanDecreaseAccuracy)) %>%
slice_head(n = 10)

ggplot(rf_importance_df, aes(x = reorder(Variable, MeanDecreaseAccuracy), y = MeanDecreaseAccuracy)) +
    geom_bar(stat = "identity", fill = "#2196F3", alpha = 0.8) +
    coord_flip() +
    labs(title = "Top 10 Most Important Variables in Random Forest Model",
         x = "Variables", y = "Mean Decrease Accuracy") +
    theme_minimal()
```

------------------------------------------------------------------------

## 8. Model Evaluation and Comparison

### 8.1 Model Predictions

```{r model-predictions}
# CART predictions
cart_pred <- predict(cart_model_pruned, test_data, type = "class")
cart_prob <- predict(cart_model_pruned, test_data, type = "prob")

# Random Forest predictions
rf_pred <- predict(rf_model, test_data, type = "class")
rf_prob <- predict(rf_model, test_data, type = "prob")

cat("Predictions completed for both models.\n")
```

### 8.2 Confusion Matrix Analysis

```{r confusion-matrices}
# CART confusion matrix
cart_cm <- confusionMatrix(cart_pred, test_data$Kelayakan.Kredit, positive = "Baik")
print("CART Model Confusion Matrix:")
print(cart_cm)

# Random Forest confusion matrix
rf_cm <- confusionMatrix(rf_pred, test_data$Kelayakan.Kredit, positive = "Baik")
print("Random Forest Model Confusion Matrix:")
print(rf_cm)
```

```{r confusion-matrix-plots}
# Function to create confusion matrix plot
plot_confusion_matrix <- function(cm, title, color) {
    cm_df <- as.data.frame(cm$table)
    colnames(cm_df) <- c("Actual", "Predicted", "Frequency")
    
    ggplot(cm_df, aes(x = Actual, y = Predicted, fill = Frequency)) +
        geom_tile(alpha = 0.8) +
        geom_text(aes(label = Frequency), color = "black", size = 5, fontface = "bold") +
        scale_fill_gradient(low = "white", high = color) +
        labs(title = title, x = "Actual", y = "Predicted") +
        theme_minimal() +
        theme(legend.position = "none")
}

# Create confusion matrix plots
cart_cm_plot <- plot_confusion_matrix(cart_cm, "CART Model Confusion Matrix", "#4CAF50")
rf_cm_plot <- plot_confusion_matrix(rf_cm, "Random Forest Model Confusion Matrix", "#2196F3")

# Display plots side by side
grid.arrange(cart_cm_plot, rf_cm_plot, ncol = 2)
```

### 8.3 ROC Curve Analysis

```{r roc-analysis}
# Calculate ROC curves
cart_roc <- roc(as.numeric(test_data$Kelayakan.Kredit) - 1, cart_prob[, "Baik"])
rf_roc <- roc(as.numeric(test_data$Kelayakan.Kredit) - 1, rf_prob[, "Baik"])

# Create ROC curve data frame
create_roc_df <- function(roc_obj, model_name) {
    data.frame(
        Specificity = roc_obj$specificities,
        Sensitivity = roc_obj$sensitivities,
        Model = model_name,
        AUC = round(auc(roc_obj), 3)
    )
}

cart_roc_df <- create_roc_df(cart_roc, "CART")
rf_roc_df <- create_roc_df(rf_roc, "Random Forest")
roc_combined <- rbind(cart_roc_df, rf_roc_df)

# Plot ROC curves
ggplot(roc_combined, aes(x = 1 - Specificity, y = Sensitivity, color = Model)) +
    geom_line(size = 1.2, alpha = 0.8) +
    geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "gray50") +
    scale_color_manual(
        values = c("CART" = "#4CAF50", "Random Forest" = "#2196F3"),
        labels = c(
            paste("CART (AUC =", unique(cart_roc_df$AUC), ")"),
            paste("Random Forest (AUC =", unique(rf_roc_df$AUC), ")")
        )
    ) +
    labs(
        title = "ROC Curves Comparison",
        x = "False Positive Rate (1 - Specificity)",
        y = "True Positive Rate (Sensitivity)",
        color = "Model"
    ) +
    theme_minimal() +
    theme(legend.position = "bottom")
```

### 8.4 Model Performance Comparison

```{r model-comparison}
# Create comprehensive model comparison table
model_comparison <- data.frame(
    Model = c("CART (Pruned)", "Random Forest"),
    Accuracy = c(cart_cm$overall["Accuracy"], rf_cm$overall["Accuracy"]),
    Sensitivity = c(cart_cm$byClass["Sensitivity"], rf_cm$byClass["Sensitivity"]),
    Specificity = c(cart_cm$byClass["Specificity"], rf_cm$byClass["Specificity"]),
    Precision = c(cart_cm$byClass["Pos Pred Value"], rf_cm$byClass["Pos Pred Value"]),
    F1_Score = c(cart_cm$byClass["F1"], rf_cm$byClass["F1"]),
    AUC = c(auc(cart_roc), auc(rf_roc)),
    Kappa = c(cart_cm$overall["Kappa"], rf_cm$overall["Kappa"])
)

# Display comparison table
kable(model_comparison, 
      digits = 4,
      caption = "Model Performance Comparison",
      col.names = c("Model", "Accuracy", "Sensitivity", "Specificity", 
                   "Precision", "F1-Score", "AUC", "Kappa"))
```

```{r performance-visualization}
# Visualize model performance metrics
model_comparison_long <- model_comparison %>%
    pivot_longer(
        cols = c("Accuracy", "Sensitivity", "Specificity", "Precision", "F1_Score", "AUC", "Kappa"),
        names_to = "Metric", 
        values_to = "Value"
    )

ggplot(model_comparison_long, aes(x = Metric, y = Value, fill = Model)) +
    geom_bar(stat = "identity", position = "dodge", alpha = 0.8) +
    geom_text(aes(label = round(Value, 3)), 
              position = position_dodge(width = 0.9), 
              vjust = -0.5, size = 3) +
    scale_fill_manual(values = c("CART (Pruned)" = "#4CAF50", "Random Forest" = "#2196F3")) +
    labs(title = "Model Performance Metrics Comparison",
         x = "Performance Metric", y = "Score") +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

------------------------------------------------------------------------

## 9. Results Summary and Recommendations

```{r results-summary}
# Identify best performing model
best_model_auc <- model_comparison$Model[which.max(model_comparison$AUC)]
best_model_f1 <- model_comparison$Model[which.max(model_comparison$F1_Score)]
best_auc_score <- round(max(model_comparison$AUC), 3)
best_f1_score <- round(max(model_comparison$F1_Score), 3)

cat("üéØ ANALYSIS RESULTS SUMMARY\n")
cat("==========================\n\n")
cat("üìä Best Model by AUC:", best_model_auc, "with AUC =", best_auc_score, "\n")
cat("üìä Best Model by F1-Score:", best_model_f1, "with F1-Score =", best_f1_score, "\n\n")

cat("üîç KEY FINDINGS:\n")
cat("1. Both models show good performance for credit worthiness prediction\n")
cat("2. Data balancing improved model fairness across both classes\n")
cat("3. Model pruning reduced complexity while maintaining performance\n")
cat("4. Most important factors for credit assessment identified\n\n")

cat("üí° RECOMMENDATIONS:\n")
cat("1. Use", ifelse(best_auc_score == max(model_comparison$AUC), best_model_auc, "ensemble approach"), "for production deployment\n")
cat("2. Implement regular model retraining with new data\n")
cat("3. Consider cost-sensitive learning for real-world application\n")
cat("4. Validate model performance on external datasets\n")
```

------------------------------------------------------------------------

## 10. Save Results and Outputs

```{r save-results}
# Create output directory
if(!dir.exists("results")) dir.create("results")

# Save model comparison results
write.csv(model_comparison, "results/model_comparison.csv", row.names = FALSE)

# Save variable importance results
if(exists("cart_importance_df") && nrow(cart_importance_df) > 0) {
    write.csv(cart_importance_df, "results/cart_variable_importance.csv", row.names = FALSE)
}

if(exists("rf_importance_df")) {
    write.csv(rf_importance_df, "results/rf_variable_importance.csv", row.names = FALSE)
}

# Save model objects (optional)
# saveRDS(cart_model_pruned, "results/cart_model_pruned.rds")
# saveRDS(rf_model, "results/rf_model.rds")

cat("‚úÖ Results saved to 'results/' directory\n")
cat("‚úÖ Analysis completed successfully!\n")
```

------------------------------------------------------------------------

## üìã Session Information

```{r session-info}
sessionInfo()
```
